{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Combining the Source Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reading raw data:\n",
      "metadata; records: 45466, fields: 11\n",
      "keywords; records: 46419, fields: 2\n",
      "movies; records: 4638, fields: 18\n",
      "\n",
      "> Removing duplicate rows from each table:\n",
      "> After the removal, we end up with the following number of rows for each table:\n",
      "metadata; records: 39943, fields: 11\n",
      "keywords; records: 44447, fields: 2\n",
      "movies; records: 4570, fields: 18\n",
      "\n",
      "> Combining metadata and keywords tables using \"id\" column that is common in both tables.\n",
      "metadata + keywords --> shape: 39089, fields: 12\n",
      "\n",
      "> Combining movies and previously combined metadata+keywords table using movie titles\n",
      "df = movies + metadata + keywords --> shape: 3524, fields: 30\n"
     ]
    }
   ],
   "source": [
    "print('> Reading raw data:')\n",
    "movies = pd.read_csv('./data/movies.csv')\n",
    "metadata = pd.read_csv('./data/metadata.csv')\n",
    "keywords = pd.read_csv('./data/keywords.csv')\n",
    "print(\"metadata; records: \"+str(metadata.shape[0])+\", fields: \"+str(metadata.shape[1]))\n",
    "print(\"keywords; records: \"+str(keywords.shape[0])+\", fields: \"+str(keywords.shape[1]))\n",
    "print(\"movies; records: \"+str(movies.shape[0])+\", fields: \"+str(movies.shape[1]))\n",
    "\n",
    "print(\"\")\n",
    "print('> Removing duplicate rows from each table:')\n",
    "movies.drop_duplicates(subset='name',keep=False,inplace=True)\n",
    "metadata.drop_duplicates(subset='title',keep=False,inplace=True)\n",
    "keywords.drop_duplicates(subset='id',keep=False,inplace=True)\n",
    "print('> After the removal, we end up with the following number of rows for each table:')\n",
    "print(\"metadata; records: \"+str(metadata.shape[0])+\", fields: \"+str(metadata.shape[1]))\n",
    "print(\"keywords; records: \"+str(keywords.shape[0])+\", fields: \"+str(keywords.shape[1]))\n",
    "print(\"movies; records: \"+str(movies.shape[0])+\", fields: \"+str(movies.shape[1]))\n",
    "\n",
    "print(\"\")\n",
    "print('> Combining metadata and keywords tables using \"id\" column that is common in both tables.')\n",
    "metadata['id'] = metadata['id'].apply(lambda x: int(x))\n",
    "metadata_keywords = metadata.merge(keywords,how='inner')\n",
    "print('metadata + keywords --> shape: '+str(metadata_keywords.shape[0])+\", fields: \"+str(metadata_keywords.shape[1]))\n",
    "\n",
    "print(\"\")\n",
    "print('> Combining movies and previously combined metadata+keywords table using movie titles')\n",
    "df = movies.merge(metadata_keywords,how='inner',left_on='name',right_on='original_title')\n",
    "print('df = movies + metadata + keywords --> shape: '+str(df.shape[0])+\", fields: \"+str(df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The last table, \"df\" is the combined data from three sources and thus will be used in throughout the project. We will still manipulate the data in terms of preprocessing and feature engineering, but we do not expect any further reduction in number of rows. Still, it can happen due to corrupt data issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Transforming Features to their Correct Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the data, we see that following columns need not any initial transformation:\n",
    "* genre\n",
    "* company\n",
    "* budget\n",
    "* country\n",
    "* director\n",
    "* overview\n",
    "* tagline\n",
    "\n",
    "And the following features had to change due to:\n",
    "* released: this is a date column with dd.mm.yyyy format. For the sake of simplicity, we are only interested in the year the movies are released. Therefore we apply a transformation to extract year information from this column and write it to *year_released* column.\n",
    "\n",
    "Of course, all of the categorical features will be converted to continuous (or, at least discrete) fields before modeling stage, but for now, we are just interested in the integrity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_released'] = df.released.apply(lambda x: x[:-6][-4:])\n",
    "df[df.year_released.isin(['','1','2'])] = 0\n",
    "df['year_released'] = df.year_released.astype(int)\n",
    "df.year_released.replace(0,int(df.year_released.mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget                          302\n",
       "company                        1038\n",
       "country                          30\n",
       "director                       1596\n",
       "genre                            16\n",
       "gross                          3510\n",
       "name                           3512\n",
       "rating                            9\n",
       "released                       1772\n",
       "runtime                         116\n",
       "score                            72\n",
       "star                           1317\n",
       "votes                          3463\n",
       "writer                         2295\n",
       "year                             32\n",
       "isprofit                          2\n",
       "profitability_ratio            3510\n",
       "profitability_ratio_bucket      168\n",
       "adult                             2\n",
       "id                             3516\n",
       "imdb_id                        3516\n",
       "original_title                 3512\n",
       "overview                       3515\n",
       "popularity                     3516\n",
       "tagline                        3138\n",
       "title                          3516\n",
       "genres_edited                   907\n",
       "spoken_languages_edited         353\n",
       "production_countries_edited     261\n",
       "keywords_edited                3280\n",
       "year_released                    32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/raw_training_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
